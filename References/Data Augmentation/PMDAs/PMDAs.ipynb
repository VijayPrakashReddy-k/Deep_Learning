{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PMDAs - Poor Man's Data Augmentation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    PMDAs\n",
    "        \n",
    "        Scale; Translation; Rotation; Blurring; Image Mirroring; Color Shifting / Whitening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Mix several datasets : ImageNet >< COCO ><VOC\n",
    "\n",
    "`Manually designing DA transformations: time-consuming and labor intensive, and inappropriate transformations may reduce the generalization performance of the model.`\n",
    "\n",
    "`Even if we were to do manual DA:`\n",
    "\n",
    "    New training images/data is generated by applying random rotations, translations, or color perturbations. Such a DA process is based on \"label-preserving\" transformations and assumes that the noise model over these transformation spaces can represent with fidelity the processes that have produced the labeled images. And to the best of our knowledge has not been properly tested. This is in fact known as \"poor man's\" data augmentation (PMDA). Intuitively, data augmentation is used to teach a model about invariances in the data domain: classifying an object is often insensitive to horizontal flips or translation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
