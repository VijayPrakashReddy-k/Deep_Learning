{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Middle-Class Man's Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "        Expanding Data Sets through Elastic Distortions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Elastic Distortions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Elastic_distortion](Elastic_distortion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DropOut 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DropOut](dropout.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Remember that we drop \"neurons\" here.`\n",
    "\n",
    "    And what are neurons in CNN?\n",
    "\n",
    "        So what we learned in the class isn't what DropOut is doing. It is a special case of dropout called SpatialDropout. \n",
    "        \n",
    "      But in Keras you are implementing old DropOut.\n",
    "\n",
    "            from keras.layers import SpatialDropout2D\n",
    "            model.add(SpatialDropout2D(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \"While dropout was found to be \"very effective\" at regularizing fully-connected layers, it appears to be less powerful when used with convolution layers.\n",
    "\n",
    "    we found that applying standard dropout before 1x1 convolution layer generally increased training time, but did not prevent over-training. Since our (*Yann LeCun) network is fully convolutional and natural images exhibit strong spatial correlation, the feature map activations are also strongly correlated, and in this setting, standard dropouts failed. They invented something called SpatialDropout 2015.\n",
    "\n",
    "`Replace DropOuts with SpatialDropOut's in your networks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Batch Normalization 2015</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Batch Normalization: It was discovered upon the realization that normalization need not just be performed on the input layer, but can also be achieved on intermediate layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cutout 29 Nov 2017: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    CutOut: Image speaks better on what it is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yu4u/cutout-random-erasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cutout](cutout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mixup 27 April 2018:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mixup alpha-blends two images to construct a new training image. Mixup can train deep CNNs on convex combinations of pairs of training samples and their labels and enables deep CNNs to favor a simple linear behavior in between training samples. This behavior makes the prediction confidence transit linearly from one class to another class, thus providing smoother estimation and margin maximization. Alpha-blending not only increases the variety of training images but also works like adversarial perturbation. Thereby, mixup makes deep CNNs robust to adversarial examples and stabilizes the training of generative adversarial networks. In addition, it behaves similar to class label smoothing by mixing\n",
    "\n",
    "    class labels with the ratio λ : 1 − λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label Smoothing 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In classification tasks, class labels are often expressed as probabilities of 0 and 1. Deep CNNs commonly employ the softmax function, which never predicts an exact probability of 0 and 1. Thus, deep CNNs continue to learn increasingly larger weight parameters and make unjustly high confidence.  Label smoothing sets the class probabilities to intermediate values, such as 0.9 and 0.8. It prevents the endless pursuit of hard 0 and 1 probabilities for the estimated classes and enables the weight parameters to converge to certain values without discouraging correct classification. Mixup mixes class labels of the blended images with the ratio λ : 1−λ and has a similar contribution to label smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Smart-Augmentation -  (Mar 2017 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The goal of SA is to learn the best augmentation strategy for a given class of input data. It does this by learning to merge two or more samples in one class. This merged sample is then used to train a target network. The loss of the target network is used to inform the augmenter at the same time. This has the result of generating more data for use by the target network. This process often includes letting the network come up with unusual or unexpected but highly performance augmentation strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Smart Augmentation](Smart_Augmentation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sample Pairing 11 April 2018 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e. taking an average of two images for each pixel). Since two images are equally weighted in the mixed image, a classifier cannot correctly predict the label of the first image, unless the second image also belongs to the same class.\n",
    "\n",
    "![Smart_Augmentation](Smart_Aug.jpg)\n",
    "\n",
    "    So, training loss cannot become zero even using a huge network and the training accuracy cannot surpass about 50% on average. Even though the training accuracy will not be high with SamplePairing, both the training and validation accuracy quickly improves when we stop the SamplePairing as the final fine-tuning phase of training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![training](traing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>RICAP 22 Nov 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    RICAP crops four training images and patches them to construct a new training image; it selects images and determines the cropping sizes randomly, where the size of the final image is identical to that of the original image.  RICAP also mixes class labels of the four images with ratios proportional to the areas of the four images like label smoothing in mixup. Compared to mixup, RICAP has three clear distinctions: \n",
    "    it mixes images spatially, it uses partial images by cropping, and it does not create features that are absent in the original dataset except for boundary patching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RICAP](RICAP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RICAP shares concepts with cutout, mixup, and label smoothing, and potentially overcomes their shortcomings.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RICAP](RICAP2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RICAP](RICAP3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
