{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs_x_test_tensored)\n",
    "print('!'*100)\n",
    "print(y_prob)\n",
    "# y_prob instead of outputs_x_test_tensored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            x_train_tensored, y_train_tensored, x_test_tensored, y_test_tensored = PYTORCHUTILS.get_tensored_data(x_train, y_train, x_test, y_test)\n",
    "            trainset = torch_data_utils.TensorDataset(x_train_tensored, y_train_tensored)\n",
    "            testset = torch_data_utils.TensorDataset(x_test_tensored, y_test_tensored)\n",
    "\n",
    "            nnptc_params = algoSetting.get_nnptc_params_dict()[0]\n",
    "            layers_for_network = PYTORCHUTILS.get_layers_for_network_module(nnptc_params, task_type = \"CLASSIFICATION\", first_layer_units = x_train.shape[1])\n",
    "            # Use GPU if available\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            network = PyTorchNetwork(layers_for_network).to(device)\n",
    "            network.eval()\n",
    "\n",
    "            print(\"~\"*50)\n",
    "            print(network.parameters())\n",
    "            print(\"~\"*50)\n",
    "\n",
    "            other_params_dict = PYTORCHUTILS.get_other_pytorch_params(nnptc_params, task_type = \"CLASSIFICATION\", network_params = network.parameters())\n",
    "\n",
    "            print(\"~\"*50)\n",
    "            print(\"NNPTC-PARAMS - \", nnptc_params)\n",
    "            print(\"~\"*50)\n",
    "            print(\"OTHER-PARAMS-DICT - \", other_params_dict)\n",
    "            print(\"~\"*50)\n",
    "            print(\"NEURAL-NETWORK - \", network)\n",
    "            print(\"~\"*50)\n",
    "\n",
    "            criterion = other_params_dict[\"loss_criterion\"]\n",
    "            n_epochs = other_params_dict[\"number_of_epochs\"]\n",
    "            batch_size = other_params_dict[\"batch_size\"]\n",
    "            optimizer = other_params_dict[\"optimizer\"]\n",
    "            optimizer = optim.Adam(network.parameters(), weight_decay=0.0001)\n",
    "\n",
    "            dataloader_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"shuffle\": True\n",
    "            # \"num_workers\":\n",
    "            }\n",
    "\n",
    "            train_loader = torch_data_utils.DataLoader(trainset, **dataloader_params)\n",
    "            test_loader = torch_data_utils.DataLoader(testset, **dataloader_params)\n",
    "\n",
    "            '''\n",
    "            Training the network;\n",
    "            Batchnormalization(num_features) should be equal to units_op for that layer in training config;\n",
    "            else --> RuntimeError('running_mean should contain 100 elements not 200',)\n",
    "            '''\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                batchwise_losses = []\n",
    "                average_loss = 0.0\n",
    "\n",
    "                for i, (inputs, labels) in enumerate(train_loader):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward + backward + optimize\n",
    "                    outputs = network(inputs.float())\n",
    "                    loss = criterion(outputs, labels.long())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    average_loss += loss.item()\n",
    "                    batchwise_losses.append(loss.item())\n",
    "\n",
    "                average_loss_per_epoch = old_div(average_loss,(i + 1))\n",
    "                print(\"+\"*80)\n",
    "                print(\"EPOCH - \", epoch)\n",
    "                print(\"BATCHWISE_LOSSES shape - \", len(batchwise_losses))\n",
    "                print(\"AVERAGE LOSS PER EPOCH - \", average_loss_per_epoch)\n",
    "                print(\"+\"*80)\n",
    "\n",
    "            trainingTime = time.time()-st\n",
    "            bestEstimator = network\n",
    "\n",
    "            outputs_x_test_tensored = network(x_test_tensored.float())\n",
    "            softmax = torch.nn.Softmax()\n",
    "            y_prob = softmax(outputs_x_test_tensored)\n",
    "\n",
    "            _, y_score = torch.max(outputs_x_test_tensored, 1)\n",
    "\n",
    "            y_score = y_score.tolist()\n",
    "            y_prob = y_prob.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
